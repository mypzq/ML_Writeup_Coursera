source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/rankall.R', echo=TRUE)
?lapply
source('~/rankall.R', echo=TRUE)
View(a)
?sapply
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
dat <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
new_dat <- data.frame(State=dat$State, DeathRate=dat[[deathRate_colName]], Hospital=dat$Hospital.Name)
new_dat <- data.frame(State=as.character(dat$State),
new_dat <- data.frame(State=as.character(dat$State),
DeathRate=as.numeric(dat[[deathRate_colName]]),
Hospital=as.character(dat$Hospital.Name))
rm(dat)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
?split
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
View(a)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
View(a)
View(a)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
warnings()
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankall.R', echo=TRUE)
source('~/rankhospital.R', echo=TRUE)
source('~/best.R', echo=TRUE)
source('~/best.R', echo=TRUE)
source('~/rankhospital.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
source('~/temp.r', echo=TRUE)
x <- c(0.18,-1.54,0.42,0.95)
w <- c(2,1,3,1)
source('~/CoureReg_week1.r', echo=TRUE)
source('~/CoureReg_week1.r', echo=TRUE)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x -1)
coef(fit)
data(mtcars)
names(mtcars)
fit <- lm(mtcars$mpg ~ mtcars$weight)
fit <- lm(mtcars$mpg ~ mtcars$wt)
coef(fit)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
z <- (x-mean(x))/sd(x)
z
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit <- lm(y ~ x)
coef(fit)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
install.packages("knitr")
```{r run=FALSE}
rm(list=ls())
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit1 <- lm(y ~ x)
summary(fit1)
library(mtcars)
data(mtcars)
names(mtcars)
fit2 <- lm(mtcars$outcome ~ mtcars$wt)
fit2 <- lm(mtcars$mpg ~ mtcars$wt)
summary(fit2)
M.wt<-mean(mtcars$wt)
?predict
predict(fit2,M.wt,interval = c("none", "confidence,"prediction"))
predict(fit2,M.wt,interval ="confidence")
M.wt
M.wt<-data.frame(mean(mtcars$wt))
M.wt
predict(fit2,M.wt,interval ="confidence")
M.wt
rm(list=ls())
data(mtcars)
names(mtcars)
fit2 <- lm(mtcars$mpg ~ mtcars$wt)
summary(fit2)
M.wt<-data.frame(mean(mtcars$wt))
M.wt
predict(fit2,M.wt,interval ="confidence")
predict(fit2, 1,interval ="confidence")
summary(fit2)
predict(fit2, 1)
dim(mtcars$mpg)
length(mtcars$mpg)
fit2, 1
data(mtcars)
names(mtcars)
fit2 <- lm(mtcars$mpg ~ mtcars$wt)
summary(fit2)
M.wt<-data.frame(mean(mtcars$wt))
M.wt
a <- predict(fit2, 1)
a
fit2 <- lm(mtcars$mpg ~ mtcars$wt)
summary(fit2)
a <- predict(fit2, 1)
a
x <- rnorm(15)
y <- x + rnorm(15)
predict(lm(y ~ x))
new <- data.frame(x = seq(-3, 3, 0.5))
predict(lm(y ~ x), new, se.fit = TRUE)
pred.w.plim <- predict(lm(y ~ x), new, interval = "prediction")
pred.w.clim <- predict(lm(y ~ x), new, interval = "confidence")
matplot(new$x, cbind(pred.w.clim, pred.w.plim[,-1]),
lty = c(1,2,2,3,3), type = "l", ylab = "predicted y")
data(mtcars)
names(mtcars)
fit2 <- lm(mtcars$mpg ~ mtcars$wt)
summary(fit2)
M.wt<-data.frame(mean(mtcars$wt))
M.wt
a <- predict(fit2, newdata=1)
a
a <- predict(fit2, newdata=M.wt)
data(mtcars)
names(mtcars)
fit2 <- lm(mtcars$mpg ~ mtcars$wt)
summary(fit2)
M.wt<-data.frame(c(mean(mtcars$wt))
)
M.wt<-data.frame(c(mean(mtcars$wt)))
M.wt
a <- predict(fit2, newdata=M.wt)
dim(M.wt)
rm(list=ls())
library(mtcars)
data(mtcars)
rm(list=ls())
data(mtcars)
names(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl)
fit <- lm(mpg ~ cyl + wt, data=mtcars)
summary(fit)
fit2 <- lm(mpg ~ cyl, data=mtcars)
summary(fit2)
fit3 <- lm(mpg ~ cyl + wt +cyl*wt, data=mtcars)
summary(fit3)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit4 <- lm(y ~x)
a <- hatvalues(fit4)
a
b <- dfbetas(fit4)
b
anova(fit1, fit3)
fit1 <- lm(mpg ~ cyl + wt, data=mtcars)
summary(fit1)
fit2 <- lm(mpg ~ cyl, data=mtcars)
summary(fit2)
fit3 <- lm(mpg ~ cyl + wt +cyl*wt, data=mtcars)
summary(fit3)
anova(fit1, fit3)
?lm
x<-1:10
y<-2*x;
lm(y~I(x*0.5))
lm(y~I(x*1))
rm(list=ls())
data(mtcars)
names(mtcars)
mtcars$cyl <- as.factor(mtcars$cyl)
fit1 <- lm(mpg ~ cyl + wt, data=mtcars)
summary(fit1)
fit2 <- lm(mpg ~ cyl, data=mtcars)
summary(fit2)
fit5 <- lm(mpg ~ wt, data=mtcars)
summary(fit1)
fit5 <- lm(mpg ~ wt, data=mtcars)
summary(fit5)
fit5.resid
fit5 <- lm(mpg ~ wt, data=mtcars)
summary(fit5)
fit5.residuals
names(fit5)
fit5$residuals
a <- fit5$residuals
a <- fit5$residuals
a
fit5 <- lm(mpg ~ wt, data=mtcars)
summary(fit5)
a <- fit5$residuals
fit6 <-lm(a ~ cyl)
fit6 <-lm(a ~ mtcars$cyl)
fit6 <-lm(a ~ mtcars$cyl)
summary(fit6)
rm(list-ls())
library(AppliedPredictiveModeling)
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
InTrain <- createDataPartition(segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[InTrain,]
testing <- segmentationOriginal[-InTrain,]
set.seed(125)
model_1 <- train(segmentationOriginal$Case ~ .,method="rpart",data=training)
model_1 <- train(Case ~ .,method="rpart",data=training)
print(model_1$finalModel)
fancyRpartplot(model_1$finalModel)
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartplot(model_1$finalModel)
library(rattle)
fancyRpartplot(model_1$finalModel)
fancyRpartPlot(model_1$finalModel)
Plot(model_1$finalModel)
plot(model_1$finalModel)
plot(model_1$finalModel,uniform-TRUE)
plot(model_1$finalModel,uniform=TRUE)
text(model_1$finalModel, use.n=TRUE, all=TRUE)
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
InTrain <- createDataPartition(segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[InTrain,]
testing <- segmentationOriginal[-InTrain,]
set.seed(125)
model_1 <- train(Case ~ .,method="rpart",data=training)
print(model_1$finalModel)
library(rattle)
plot(model_1$finalModel,uniform=TRUE)
text(model_1$finalModel, use.n=TRUE, all=TRUE)
print(model_1$finalModel)
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
InTrain <- createDataPartition(segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[InTrain,]
testing <- segmentationOriginal[-InTrain,]
set.seed(125)
model_1 <- train(Case ~ .,method="rpart",data=training)
print(model_1$finalModel)
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
InTrain <- createDataPartition(segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[InTrain,]
testing <- segmentationOriginal[-InTrain,]
model_1 <- train(Case ~ .,method="rpart",data=training)
print(model_1$finalModel)
plot(model_1$finalModel,uniform=TRUE)
text(model_1$finalModel, use.n=TRUE, all=TRUE)
training <- subset(segmentationOriginal,segmentationOriginal$Case="Train")
training <- subset(segmentationOriginal,segmentationOriginal$Case=="Train")
training <- subset(segmentationOriginal,segmentationOriginal$Case=="Train")[,-2]
View(training)
testing <- subset(segmentationOriginal,segmentationOriginal$Case=="Test")[,-2]
model_1 <- train(Class ~ .,method="rpart",data=training)
print(model_1$finalModel)
plot(model_1$finalModel,uniform=TRUE)
text(model_1$finalModel, use.n=TRUE, all=TRUE)
print(model_1$finalModel)
plot(model_1$finalModel)
text(model_1$finalModel)
library(pgmm)
install.packages("PGM2")
library(pgm2)
library(pgmm)
data(olive)
library(PGM2)
data(olive)
install.packages("pgmm")
install.packages("C:/Users/bop/Downloads/pgmm_1.0.tar.gz", repos = NULL, type = "source")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
model_1 <- train(Area ~ .,method="rpart",data=olive)
View(olive)
newdata = as.data.frame(t(colMeans(olive)))
pred <- predict(model_1,newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
data(SAheart)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
>glm
?glm
set.seed(13234)
fit_3 <- glm(chd ~  age + alcohol + obesity + tabacco + typea +ldl, family="binomial")
fit_3 <- glm(chd ~  age + alcohol + obesity + tabacco + typea +ldl, data=trainSA,family="binomial")
fit_3 <- glm(chd ~  age + alcohol + obesity + tobacco + typea +ldl, data=trainSA,family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
a <-missclass(trainSA$chd,predict(fit_3))
a <-missClass(trainSA$chd,predict(fit_3))
b <-missClass(testSA$chd,predict(fit_3),testSA[,c(9,8,7,2,6,3)])
b <-missClass(testSA$chd,predict(fit_3),testSA])
b <-missClass(testSA$chd,predict(fit_3,testSA))
a <-missClass(trainSA$chd,predict(fit_3,trainSA)
b <-missClass(testSA$chd,predict(fit_3,testSA))
a <-missClass(trainSA$chd,predict(fit_3,trainSA))
fit_3 <- glm(chd ~  age + alcohol + obesity + tobacco + typea +ldl, data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
a <-missClass(trainSA$chd,predict(fit_3,trainSA))
b <-missClass(testSA$chd,predict(fit_3,testSA))
family="binomial"
family="binomial"
fit_3 <- glm(chd ~  age + alcohol + obesity + tobacco + typea +ldl, data=trainSA,family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
a <-missClass(trainSA$chd,predict(fit_3,trainSA))
b <-missClass(testSA$chd,predict(fit_3,testSA))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fit_3 <- glm(chd ~  age + alcohol + obesity + tobacco + typea +ldl, data=trainSA,family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
a <-missClass(trainSA$chd,predict(fit_3,trainSA))
b <-missClass(testSA$chd,predict(fit_3,testSA))
fit_3 <- train(chd ~  age + alcohol + obesity + tobacco + typea +ldl, data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
a <-missClass(trainSA$chd,predict(fit_3,trainSA))
b <-missClass(testSA$chd,predict(fit_3,testSA))
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
fit4<-train(y~.,data=vowel.train,method="rf")
fit4<-train(y~.,data=vowel.train,method="rf")
?varImp
d<-varimp(fit4)
d<-varImp(fit4)
d
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
fit4<-train(y~.,data=vowel.train,method="rf")
d<-varImp(fit4)
d
d
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
fit4<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
d<-varImp(fit4)
d
d<-varImp(fit4$finalMode)
d
set.seed(33833)
#fit4<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
fit4<-randomForrest(y~.,data=vowel.train)
set.seed(33833)
#fit4<-train(y~.,data=vowel.train,method="rf",prox=TRUE)
fit4<-randomForest(y~.,data=vowel.train)
d<-varImp(fit4$finalMode)
d<-varImp(fit4)
d
rm(list=ls())
if(!(exists("raw_train")&exists("raw_test"))){
raw_data <- read.csv("pml-training.csv")
raw_Model_test <- read.csv("pml-testing.csv")
}
##feature selection
#belt,forearm,arm and dumbell
setwd("C:/Users/bop/ML_Writeup_Coursera")
rm(list=ls())
if(!(exists("raw_train")&exists("raw_test"))){
raw_data <- read.csv("pml-training.csv")
raw_Model_test <- read.csv("pml-testing.csv")
}
##feature selection
#belt,forearm,arm and dumbell
tmp<-!apply(is.na(raw_Model_test), 2, all)
new_data<-raw_data[,tmp]
new_Model_test<-raw_Model_test[,tmp]
tmp<-names(new_data)[grep("belt|forearm|arm|dumbell|classe",names(new_data))]
new_data<-new_data[,tmp]
tmp<-names(new_Model_test)[grep("belt|forearm|arm|dumbell|problem",names(new_Model_test))]
new_Model_test<-new_Model_test[,tmp]
library(caret)
set.seed(1234)
set.seed(0)
Intrain <- createDataPartition(y = new_data$classe, p=0.7,list=FALSE)
Training <- new_data[Intrain,]
Testing  <- new_data[-Intrain,]
preP <- preProcess(Training[,-40], method = "pca", thresh = 0.98)
trainP <- predict(preP,Training[,-40])
modelF1 <- train(Training$classe ~ .,method="rf",data=trainP)
library(randomForest)
set.seed(0)
Intrain <- createDataPartition(y = new_data$classe, p=0.7,list=FALSE)
Training <- new_data[Intrain,]
Testing  <- new_data[-Intrain,]
preP <- preProcess(Training[,-40], method = "pca", thresh = 0.98)
trainP <- predict(preP,Training[,-40])
modelF1 <- train(Training$classe ~ .,method="rf",data=trainP)
save(modelF1, "modelF1.RData")
ls
getwd()
save(modelF1, "modelF1.RData")
save(modelF1, "modelF1.RData")
?save
save(modelF1, file="modelF1.RData")
testP<-predict(preP,Testing[,-40])
a<-confusionMatrix(Testing$classe,predict(modelF1,testP))
a$table
testModel<-predict(preP,new_Model_test[,-40])
a<-confusionMatrix(Testing$classe,predict(modelF1,testP))
a<-confusionMatrix(Testing$classe,predict(modelF1,testModel))
testModel<-predict(preP,new_Model_test[,-40])
finalTest<-predict(modelF1,testModel)
a<-confusionMatrix(new_Model_test$classe,finalTest)
finalTest
modelF2 <- train(Training$classe ~ .,method="gbm",data=trainP)
answers = finalTest
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
getwd()
varImpPlot(modelF1$finalModel, sort = TRUE, type = 1, pch = 19, col = 1, cex = 1,
main = "Importance of the Individual Principal Components")
varImpPlot(modelF1$finalModel, sort = TRUE, type = 1, pch = 19, col = 1, cex = 1)
varImpPlot(modelF1$finalModel, sort = TRUE, type = 1)
varImpPlot(modelF1$finalModel)
plot(ModelF1)
plot(modelF1)
modelF1
modelF1 <- load(modelF1.RDATA)
modelF1 <- load(modelF1.RData)
getwd()
load(modelF1.RData)
load(modelF1.RData)
load("modelF1.RData")
load("modelF1.RData")
a<-confusionMatrix(Testing$classe,testResult)
testResult<-predict(modelF1,testP)
R
a<-confusionMatrix(Testing$classe,testResult)
a
ls()
search()
testP<-predict(preP,Testing[,-40])
testResult<-predict(modelF1,testP)
a<-confusionMatrix(Testing$classe,testResult)
a
testP<-predict(preP,Testing[,-40])
a<-confusionMatrix(Testing$classe,predict(modelF1,testP))
a$table
testResult<-predict(modelF1,testP)
a<-confusionMatrix(Testing$classe,testResult)
a
modelF1<-load("modelF1.RData") #load saved model because it takes over 1 hour to train.
load("modelF1.RData") #load saved model because it takes over 1 hour to train.
plot(modelF1)
modelF1
load("modelF1.RData") #load saved model because it takes over 1 hour to train.
plot(modelF1)
modelF1
testResult<-predict(modelF1,testP)
```
We can now compare the pridicted values with the real values:
a<-confusionMatrix(Testing$classe,testResult)
a
